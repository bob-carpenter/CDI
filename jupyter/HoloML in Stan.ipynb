{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880e629e-b130-4ab1-aeac-24dc1eb17f5a",
   "metadata": {},
   "source": [
    "# HoloML in Stan\n",
    "### Brian Ward, Bob Carpenter, and David Barmherzig\n",
    "#### June 13, 2022\n",
    "\n",
    "This case study is a re-implementation of the algorithm described in [Barmherzig and Sun 2022] as a Stan model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc43f7-03a1-4cac-9385-8c4959f07bd6",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The HoloML technique is an approach to solving a specific kind of inverse problem inherent to imaging nanoscale specimens with X-ray crystallography. \n",
    "\n",
    "To solve this problem in Stan, we are able to write down the forward scientific model given by Barmherzig and Sun, including the Poisson photon distribution and censored data inherent to the physical problem.\n",
    "\n",
    "### Experimental setup \n",
    "\n",
    "In traditional coherent diffraction imaging (CDI), a radiation source, typically an X-ray, is directed at a biomolecule or other specimen of interest and diffracted. The resulting photon flux is measured by a far-field detector. This photon flux is approximately the squared magnitude of the Fourier transform of the electric field causing the diffraction. Inverting this to recover an image of the specimen is a problem usually known as *phase retrevial*. The phase retrieval problem is highly challenging and often lacks a unique solution [Barnett et al. 2020].\n",
    "\n",
    "Holographic coherent diffraction imaging (HCDI) is a variant in which the specimen is placed some distance away from a known reference object, and the data observed is the diffracted result of both the specimen and the reference. This additional reference information makes the problem identifiable. \n",
    "\n",
    "<img src=\"./figure 1.jpg\" width=400 />\n",
    "\n",
    "**TODO: Cite image or replace, ask David**\n",
    "\n",
    "The idealized version of HCDI is formulated as \n",
    "\n",
    "- Given a reference $R$, data $Y = | \\mathcal{F}( X + R ) | ^2$\n",
    "- Recover the source image $X$\n",
    "\n",
    "However, the real-world set up of these experiments introduces two additional difficulties. Data is measured from a limited number of photons, where each detector recieves photons based on a Poisson distribution (referred to in the paper as *Poisson-shot noise*). The expected number of photons each detector receives is denoted $N_p$. It is desirable that retrevial be performed when this value is small (< 10) due to the damage the radiation causes the biomolecule under observation. Secondly, to prevent damage to the detectors, the lowest frequencies are removed by a *beamstop* which censors low-frequency observations. \n",
    "\n",
    "The model presented here is able to recover reasonable images even under a regime featuring low photon counts and a beamstop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8679ae1-e9d0-41c4-a73a-95bb561b7dfe",
   "metadata": {},
   "source": [
    "## Simulating Data\n",
    "\n",
    "We simulate data from the generative model directly. This corresponds to the work done in Barmherzig and Sun, and is based on MATLAB code provided by Barmherzig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ffc9e-5cf7-4a6b-a935-9126ea816f9b",
   "metadata": {},
   "source": [
    "#### Imports and helper code\n",
    "\n",
    "Generating the data requires a few standard Python numerical libraries such as scipy and numpy. Matplotlib is also used to simplify loading in the source image and displaying results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3260fb8b-6a4b-4fc0-a956-fbecc4483264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# disable axes drawing, since we are showing images\n",
    "mpl.rc('axes.spines', top=False, bottom=False, left=False, right=False)\n",
    "mpl.rc('axes', facecolor='white')\n",
    "mpl.rc(\"xtick\", bottom=False, labelbottom=False)\n",
    "mpl.rc(\"ytick\", left=False, labelleft=False)\n",
    "mpl.rc(\"figure\", autolayout=True)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Convert a nxmx3 RGB array to a grayscale nxm array.\n",
    "\n",
    "    This function uses the same internal coefficients as MATLAB:\n",
    "    https://www.mathworks.com/help/matlab/ref/rgb2gray.html\n",
    "    \"\"\"\n",
    "    r, g, b = rgb[:, :, 0], rgb[:, :, 1], rgb[:, :, 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33fa51-143a-4a05-9119-eea801c548f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simulation parameters. \n",
    "\n",
    "To match the figures in the paper (in particular, Figure 9), we use an image of size 256x256, $N_p = 1$ (meaning each detector is expected to receive one photon), and a beamstop of size 25x25 (corresponding to a radius of 13), and a seperation `d` equal to the size of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93efec2-328d-4669-99d8-6daddc804506",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "d = N\n",
    "N_p = 1\n",
    "r = 13\n",
    "\n",
    "M1 = 2 * N \n",
    "M2 = 2 * (2 * N + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89073a4-1be0-4cf2-9be6-bae2b3500b6e",
   "metadata": {},
   "source": [
    "We can then load the source image used for these simulations. This is a picture of a [giant virus](https://en.wikipedia.org/wiki/Giant_virus) known as a mimivirus.\n",
    "\n",
    "In this model, the pixels of $X$ grayscale values represented on the interval [0, 1]. A conversion is done here from the standard RGBA encoding using the above `rgb2gray` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8d50d-1d3c-4ee3-8811-aff16bbc9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_src = rgb2gray(mpimg.imread('mimivirus.png'))\n",
    "plt.imshow(X_src, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0314a491-0fdb-4a0f-8e04-491d95d8b821",
   "metadata": {},
   "source": [
    "Additionally, we load in the reference object. \n",
    "\n",
    "The pattern used here is known as a *uniformly redundant array* (URA) [Fenimore and Cannon 1978]. It has been shown to be an optimal reference image for this kind of work, but other references (including none at all) could be used.\n",
    "\n",
    "The code used to generate this grid is omitted from this case study. Various options such as [cappy](https://github.com/bpops/cappy) exist to generate these patterns in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9dccfa-177d-45b1-8f27-6177b5afba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.loadtxt('URA.csv', delimiter=\",\", dtype=int)\n",
    "plt.imshow(R, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95232de3-2b02-40cb-8f9f-b6b83bb49e2d",
   "metadata": {},
   "source": [
    "We can then create the specimen-reference hybrid image by concatenating the $X$ image, a matrix of zeros, and the reference $R$. In the true experiment, this is done by placing the specimen some distance `d` away from the reference, with opaque material between. Traditionally, this distance is the same as the size of the specimen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397dc9d-e8b4-4565-ae3b-a7fbe143d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0R = np.concatenate([X_src, np.zeros((N,d)), R], axis=1)\n",
    "plt.imshow(X0R, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb38a63-92ef-4362-b4c4-3688e8b7dba8",
   "metadata": {},
   "source": [
    "We can simulate the diffraction of an X-ray by taking the absolute value squared of the 2-dimensional oversampled FFT of this hybrid object. \n",
    "\n",
    "The oversampled FFT (denoted $\\mathcal{F}$ in the paper) corresponds to padding the image in both dimensions with zeros until it is a desired size. For our case, we define the size of the padded image, `M1` by `M2`, to be two times the size of our hybrid image, so the resulting FFT is twice oversampled. This is the oversampling ratio traditionally used for this problem, however Barmherzig and Sun also showed that this model can operate with less oversampling as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2925e-77be-4f30-9ea7-b979cf4931d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.abs(np.fft.fft2(X0R, s=(M1, M2))) ** 2\n",
    "plt.imshow(np.fft.fftshift(np.log1p(Y)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8f2fe-31e4-4016-9018-37dcfd12a8de",
   "metadata": {},
   "source": [
    "We can then simulate the data retrieval process with a Poisson random number generator.\n",
    "\n",
    "We fix the seed here to ensure the same fake data is generated each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3fe7a-8b2c-4c76-ab20-377b4219e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = N_p / Y.mean()\n",
    "Y_tilde = stats.poisson.rvs(rate * Y, random_state=1234)\n",
    "plt.imshow(np.fft.fftshift(np.log1p(Y_tilde)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129090e8-40bd-4b82-963e-834ae0774d6d",
   "metadata": {},
   "source": [
    "Finally, we need to remove the low frequency content of the data. This is caused in the physical experiment by the inclusion of a \"beamstop\", which protects the instrument used by preventing the strongest parts of the beam from directly shining on the detectors.\n",
    "\n",
    "In our model, the beamstop is represented in the model by $\\mathcal{B}$, a matrix of 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77193bce-dd6e-454f-b59e-135009fedf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_cal = np.ones((M1,M2), dtype=int)\n",
    "B_cal[M1 // 2 - r + 1: M1 // 2 + r, M2 // 2 - r + 1: M2 // 2 + r] = 0\n",
    "B_cal = np.fft.ifftshift(B_cal)\n",
    "# Sanity check\n",
    "assert (M1 * M2 - B_cal.sum()) == (( 2 * r - 1)**2)\n",
    "plt.imshow(np.fft.fftshift(B_cal), cmap=\"gray\", vmin=0, vmax=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06359fda-d7a4-4302-a63d-6abb97cb3d0c",
   "metadata": {},
   "source": [
    "We can then use this matrix $\\mathcal{B}$ as a mask on our simulated data. After removing these elements from the simulated data, we have the final input which is used in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e40ec3-89bc-4544-9845-fbc53f53e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tilde *= B_cal\n",
    "plt.imshow(np.fft.fftshift(np.log(1 + Y_tilde)), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdc7a3-f352-4105-a9ab-b165e2ff45b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stan Model Code\n",
    "\n",
    "The Stan model code is a direct translation of the log density of the forward model described in the paper and used above, with the following notes:\n",
    "\n",
    "- The FFT described in the paper is an \"oversampled\" FFT. This corresponds to embedding the image in a larger array of zeros. We write an overload of the `fft2` function which implements this behavior.\n",
    "- A prior is added to impose an L2 penalty on adjacent pixels. This prior induces a Gaussian blur on the result, and it is not strictly necessary for running the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3f7ab9-6abb-4ae5-b8b7-9734bc989808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use https://pypi.org/project/cmdstanjupyter/ to display the model inline\n",
    "%load_ext cmdstanjupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d08b95-9f15-4bbc-bb9c-0c11f0195a35",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "More walk through of code, comment on more efficient construction, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4208c5-056f-48b3-870b-67a7df65d180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%stan HoloML_model\n",
    "/**\n",
    " * Preliminary sketch of model (equations 2.2, 2.3) from:\n",
    " *\n",
    " * David A. Barmherzig and Ju Sun. 2022. Towards practical holographic\n",
    " * coherent diffraction imaging via maximum likelihood estimation.\n",
    " * arXiv 2105.11512v2.\n",
    " */\n",
    "\n",
    "functions {\n",
    "  /**\n",
    "   * Return M1 x M2 matrix of 1 values with blocks in corners set to\n",
    "   * 0, where the upper left is (r x r), the upper right is (r x r-1),\n",
    "   * the lower left is (r-1 x r), and the lower right is (r-1 x r-1).\n",
    "   * This corresponds to zeroing out the lowest-frequency portions of\n",
    "   * an FFT.\n",
    "   * @param M1 number of rows\n",
    "   * @param M2 number of cols\n",
    "   * @param r block dimension\n",
    "   * @return matrix of 1 values with 0-padded corners\n",
    "   */\n",
    "  matrix pad_corners(int M1, int M2, int r) {\n",
    "    matrix[M1, M2] B_cal = rep_matrix(1, M1, M2);\n",
    "    if (r == 0) {\n",
    "      return B_cal;\n",
    "    }\n",
    "    // upper left\n",
    "    B_cal[1 : r, 1 : r] = rep_matrix(0, r, r);\n",
    "    // upper right\n",
    "    B_cal[1 : r, M2 - r + 2 : M2] = rep_matrix(0, r, r - 1);\n",
    "    // lower left\n",
    "    B_cal[M1 - r + 2 : M1, 1 : r] = rep_matrix(0, r - 1, r);\n",
    "    // lower right\n",
    "    B_cal[M1 - r + 2 : M1, M2 - r + 2 : M2] = rep_matrix(0, r - 1, r - 1);\n",
    "    return B_cal;\n",
    "  }\n",
    "  \n",
    "  /**\n",
    "   * Return the matrix corresponding to the fast Fourier\n",
    "   * transform of Z after it is padded with zeros to size\n",
    "   * N by M\n",
    "   * When N by M is larger than the dimensions of Z,\n",
    "   * this computes an oversampled FFT.\n",
    "   *\n",
    "   * @param Z matrix of values\n",
    "   * @param N number of rows desired (must be >= rows(Z))\n",
    "   * @param M number of columns desired (must be >= cols(Z))\n",
    "   * @return the FFT of Z padded with zeros\n",
    "   */\n",
    "  complex_matrix fft2(complex_matrix Z, int N, int M) {\n",
    "    int r = rows(Z);\n",
    "    int c = cols(Z);\n",
    "    if (r > N) {\n",
    "      reject(\"N must be at least rows(Z)\");\n",
    "    }\n",
    "    if (c > M) {\n",
    "      reject(\"M must be at least cols(Z)\");\n",
    "    }\n",
    "    \n",
    "    complex_matrix[N, M] pad = rep_matrix(0, N, M);\n",
    "    pad[1 : r, 1 : c] = Z;\n",
    "    \n",
    "    return fft2(pad);\n",
    "  }\n",
    "}\n",
    "data {\n",
    "  int<lower=0> N; // image dimension\n",
    "  matrix<lower=0, upper=1>[N, N] R; // registration image\n",
    "  int<lower=0, upper=N> d; // separation between sample and registration image\n",
    "  int<lower=N> M1; // rows of padded matrices\n",
    "  int<lower=2 * N + d> M2; // cols of padded matrices\n",
    "  int<lower=0, upper=M1> r; // beamstop radius. replaces omega1, omega2 in paper\n",
    "  \n",
    "  real<lower=0> N_p; // avg number of photons per pixel\n",
    "  array[M1, M2] int<lower=0> Y_tilde; // observed number of photons\n",
    "  \n",
    "  real<lower=0> sigma; // standard deviation of pixel prior.\n",
    "}\n",
    "transformed data {\n",
    "  matrix[M1, M2] B_cal = pad_corners(M1, M2, r);\n",
    "  matrix[d, N] separation = rep_matrix(0, d, N);\n",
    "}\n",
    "parameters {\n",
    "  matrix<lower=0, upper=1>[N, N] X;\n",
    "}\n",
    "model {\n",
    "  // prior - penalizing L2 on adjacent pixels\n",
    "  for (i in 1 : rows(X) - 1) {\n",
    "    X[i] ~ normal(X[i + 1], sigma);\n",
    "  }\n",
    "  for (j in 1 : cols(X) - 1) {\n",
    "    X[ : , j] ~ normal(X[ : , j + 1], sigma);\n",
    "  }\n",
    "  \n",
    "  // likelihood\n",
    "  \n",
    "  // object representing specimen and reference together\n",
    "  matrix[N, 2 * N + d] X0R = append_col(X, append_col(separation, R));\n",
    "  // observed signal - squared magnitude of the (oversampled) FFT\n",
    "  matrix[M1, M2] Y = abs(fft2(X0R, M1, M2)) .^ 2;\n",
    "  \n",
    "  real N_p_over_Y_bar = N_p / mean(Y);\n",
    "  matrix[M1, M2] lambda = N_p_over_Y_bar * Y;\n",
    "  \n",
    "  for (m1 in 1 : M1) {\n",
    "    for (m2 in 1 : M2) {\n",
    "      if (B_cal[m1, m2]) {\n",
    "        Y_tilde[m1, m2] ~ poisson(lambda[m1, m2]);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc413be2-debb-498f-b617-9135bb50e206",
   "metadata": {},
   "source": [
    "### Digression: Efficiency\n",
    "\n",
    "The above model is coded in a fashion targetting readability and attempting to stick closely to the mathematical formulation of the process. However, this does lead to an inefficent condition inside the tighest loop of the model to handle the beamstop occlusion. \n",
    "\n",
    "In practice, it is possible to avoid this conditional by changing how the data is stored..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd160cb7-6562-4d2e-9d4a-f648b251ecc6",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Now that we have our simulated data and our generative model, we can attempt to recover the image. \n",
    "\n",
    "The Stan model needs all of the same information the generative model did, except it is supplied with $\\tilde{Y}$ instead of the true image $X$, plus a scale parameter for the prior, $\\sigma$. Smaller values of $\\sigma$ (approaching 0) lead to increasing amounts of blur in the resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0add6dea-6a0e-427d-aab2-dbb5bd01055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1 # prior smoothing\n",
    "data = {\n",
    "    \"N\": N,\n",
    "    \"R\": R,\n",
    "    \"d\": N,\n",
    "    \"M1\": M1,\n",
    "    \"M2\": M2,\n",
    "    \"Y_tilde\": Y_tilde,\n",
    "    \"r\": r,\n",
    "    \"N_p\": N_p,\n",
    "    \"sigma\": sigma\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c794fb2-eaf6-4450-bf6e-a56503338357",
   "metadata": {},
   "source": [
    "Here we use optimization via the limited-memory quasi-Newton L-BFGS algorithm. This method has a bit more curvature information than what is available to the conjugate gradient approach, but less than the second order trust-region method, used in the paper. This should take a few (1-3) minutes, depending on the machine you are running on.\n",
    "\n",
    "It is also possible to sample the model using the No-U-Turn Sampler (NUTS), but evaluations of this are out of the scope of this case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20463cb7-458f-43f0-bea7-ca0cba8b6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fit = HoloML_model.optimize(data, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2665ab-c96e-4bb0-bb34-5bf22109bb84",
   "metadata": {},
   "source": [
    "We can then plot the recovered image alongside the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d70f1-025e-4aa0-9b3c-f4978d8019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "ax1.imshow(X_src, cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax1.set_title(\"True Image\")\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.imshow(fit.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax2.set_title(\"Recovered Image\\n(sigma = 1)\")\n",
    "ax2.set_axis_off()\n",
    "\n",
    "# blank third image -- used in later comparison\n",
    "ax3.imshow([[1]], cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax3.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e757be-d935-4c4d-b3be-b9228014fa21",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prior tuning\n",
    "\n",
    "The above choice of $\\sigma = 1$ has a very slight effect on the output image. It is also interesting to observe the effect of a smaller (i.e. stronger) value such as 0.05. This imposes a greater penalty on adjacent pixels which are significantly different than each other, smoothing out the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35836cfc-7d1e-4d1c-a0b0-cab8392b7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_smoothing = data.copy()\n",
    "data_smoothing['sigma'] = 0.05\n",
    "\n",
    "%time fit_smooth = HoloML_model.optimize(data_smoothing, inits=1, seed=5678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba77ca8-8501-4022-8641-93fae9c3da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3.imshow(fit_smooth.stan_variable(\"X\"), cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax3.set_title(\"Recovered Image\\n(sigma = 0.05)\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e876d80-0cd6-4eaa-9460-95369e28520a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reproducibility \n",
    "The following versions were used to produce this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639004d-4f3f-438a-a122-6ae247018ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w -p cmdstanpy,cmdstanjupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0ea95-d908-4114-88bc-b41d541c9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmdstanpy\n",
    "print(\"CmdStan:\", cmdstanpy.utils.cmdstan_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7753c0-aa64-4ee6-8893-b6ecbea8abf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "- David A. Barmherzig and Ju Sun, \"Towards practical holographic coherent diffraction imaging via maximum likelihood estimation,\" Opt. Express 30, 6886-6906 (2022)\n",
    "- A. H. Barnett, C. L. Epstein, L. F. Greengard, and J. F. Magland, “Geometry of the phase retrieval problem,” Inverse Probl. 36(9), 094003 (2020)\n",
    "- E. E. Fenimore and T. M. Cannon, \"Coded aperture imaging with uniformly redundant arrays,\" Appl. Opt. 17, 337-347 (1978)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2cc4e-ec29-42e6-adfb-4641e6653ed0",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
